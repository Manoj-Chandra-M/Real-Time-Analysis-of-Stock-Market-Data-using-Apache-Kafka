{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9832dbd",
   "metadata": {},
   "source": [
    "## Kafka Producer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfae7bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6589ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f3f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['Mention your public IP here from EC2 instance:9092'], \n",
    "                         api_version=(0,11,5),\n",
    "                         value_serializer=lambda x: \n",
    "                         dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f3649",
   "metadata": {},
   "source": [
    "**This code above creates a KafkaProducer object configured to connect to a Kafka broker running on an EC2 instance at a specified IP address and port, using Kafka API version 0.11.5, and serializing message values to JSON format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba89fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "producer.send('demo_test_1', value=\"{'day':'night'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f3eac",
   "metadata": {},
   "source": [
    "**The first parameter is the name of the Kafka topic to which the message will be sent, which is 'demo_test_1' in this case.**\n",
    "\n",
    "**The second parameter is the value of the message being sent. It's a string containing JSON data: \"{ 'day': 'night' }\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\MS Universities\\U of T\\Data Engineering Learning\\Stock_market_project\\indexProcessed.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    dict_stock = df.sample(1).to_dict(orient=\"records\")[0]\n",
    "    producer.send('demo_test_1', value=dict_stock)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183051ed",
   "metadata": {},
   "source": [
    "**The stock market data is simulated in real-time and run in loop, the data is sampled to get uniqueness. Send the data one by one to kafka producer and it will produce the data and send to kafka server.** \n",
    "\n",
    "**Changes reflected in producer will be immediately seen in the consumer terminal which explains real time analytics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02821d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.flush() #clear data from kafka server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9979407",
   "metadata": {},
   "source": [
    "Flush removes the old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf82b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
